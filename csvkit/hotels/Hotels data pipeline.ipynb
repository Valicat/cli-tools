{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotels data pipeline\n",
    "====================\n",
    "\n",
    "We'll use this notebook to show how to build a data pipeline to process data. This could also be rerun with new data if need be.* \n",
    "\n",
    "We'll be using Hotel Occupancy Tax Receipts data, which can be used to see which hotels around the state pull in the most money. For more information about the data itself, see this [README.md](https://github.com/utdata/cli-tools/blob/master/hoteltax/README.md).\n",
    "\n",
    "\n",
    "## The Goal\n",
    "\n",
    "* We're going to download one year of monthly files.\n",
    "* We'll convert them into well-formatted csv files.\n",
    "* We'll then put all those monthly files into a single big file.\n",
    "* We'll then pull out just hotels in Austin.\n",
    "\n",
    "## Getting the data\n",
    "\n",
    "We'll use a new command called `curl` to download our data. For more information on curl, you can read the [man page](https://curl.haxx.se/docs/manpage.html) or this [handy tip sheet](http://www.thegeekstuff.com/2012/04/curl-examples/), which is much more understandable.\n",
    "\n",
    "Since we are in a Bash notebook, we can use our command-line tools. Let's make sure we know where we are. Type in `pwd` in the prompt below and then do shift-return to execute the command.\n",
    "\n",
    "# fix this!!!!!!!!\n",
    "Fix this so everything always runs out of /hotels/. Switch back and forth is kinda nuts. Maybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/code/cli-tools/csvkit/hotels\r\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we need to be inside the data folder when we download or data, so let us move there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christian/Documents/code/cli-tools/csvkit/hotels/data\r\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use `curl` to pull down a single monthly hotel tax file. If you read about the tax data, you'll see you can get it from the comptroller, but they have some naming issues, so to help with this assignment, I've saved the data and we'll pull it down from this github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  6 2769k    6  175k    0     0   117k      0  0:00:23  0:00:01  0:00:22  172k\r",
      " 58 2769k   58 1631k    0     0   657k      0  0:00:04  0:00:02  0:00:02  812k\r",
      "100 2769k  100 2769k    0     0   842k      0  0:00:03  0:00:03 --:--:--  985k\r\n"
     ]
    }
   ],
   "source": [
    "curl -O -L https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down that `curl` statement.\n",
    "\n",
    "* `curl` is the command. I think of it as \"capture URL\"\n",
    "* `-O` (that's capital O, not zero). This outputs result to a file to your computer instead of to your screen.\n",
    "* `-L` stands for `--location`, and it will allow the request to follow a redirect link. It's good to use it.\n",
    "* And then we have the url of the file.\n",
    "\n",
    "Let's check that the file made it to our computer, and if some data in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 67304\r\n",
      "-rw-r--r--  1 christian  staff  2836275 Jul 10 22:58 hotl1501.csv\r\n",
      "-rw-r--r--  1 christian  staff  2798838 Jul 10 21:20 hotl1502.csv\r\n",
      "-rw-r--r--  1 christian  staff  2804719 Jul 10 21:20 hotl1503.csv\r\n",
      "-rw-r--r--  1 christian  staff  2792044 Jul 10 21:20 hotl1504.csv\r\n",
      "-rw-r--r--  1 christian  staff  2805369 Jul 10 21:20 hotl1505.csv\r\n",
      "-rw-r--r--  1 christian  staff  2884019 Jul 10 21:20 hotl1506.csv\r\n",
      "-rw-r--r--  1 christian  staff  2881094 Jul 10 21:20 hotl1507.csv\r\n",
      "-rw-r--r--  1 christian  staff  2962019 Jul 10 21:20 hotl1508.csv\r\n",
      "-rw-r--r--  1 christian  staff  2988669 Jul 10 21:20 hotl1509.csv\r\n",
      "-rw-r--r--  1 christian  staff  2705594 Jul 10 21:20 hotl1510.csv\r\n",
      "-rw-r--r--  1 christian  staff  2944794 Jul 10 21:20 hotl1511.csv\r\n",
      "-rw-r--r--  1 christian  staff  3034819 Jul 10 21:20 hotl1512.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is there, and it is 2.8M. Pretty big file.\n",
    "\n",
    "Because our file names are well formatted, we can pull down multiple files at the same time. The file names have `hotl` followed by the year and month: `YYMM`. There is a feature in `curl` where we can get sequences of alphanumeric series in the url by using [], like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[1/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1501.csv --> hotl1501.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1501.csv\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  9 2769k    9  255k    0     0   147k      0  0:00:18  0:00:01  0:00:17  147k\r",
      " 45 2769k   45 1263k    0     0   461k      0  0:00:06  0:00:02  0:00:04  461k\r",
      " 88 2769k   88 2449k    0     0   655k      0  0:00:04  0:00:03  0:00:01  655k\r",
      "100 2769k  100 2769k    0     0   725k      0  0:00:03  0:00:03 --:--:--  725k\r\n",
      "\r\n",
      "[2/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1502.csv --> hotl1502.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1502.csv\r\n",
      "\r",
      " 23 2732k   23  639k    0     0   703k      0  0:00:03 --:--:--  0:00:03  703k\r",
      " 72 2732k   72 1972k    0     0  1028k      0  0:00:02  0:00:01  0:00:01 1320k\r",
      "100 2732k  100 2732k    0     0  1151k      0  0:00:02  0:00:02 --:--:-- 1428k\r\n",
      "\r\n",
      "[3/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1503.csv --> hotl1503.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1503.csv\r\n",
      "\r",
      "  1 2738k    1 31975    0     0  61313      0  0:00:45 --:--:--  0:00:45 61313\r",
      " 48 2738k   48 1327k    0     0   872k      0  0:00:03  0:00:01  0:00:02 1296k\r",
      "100 2738k  100 2738k    0     0  1106k      0  0:00:02  0:00:02 --:--:-- 1387k\r\n",
      "\r\n",
      "[4/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1504.csv --> hotl1504.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1504.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 10 2726k   10  287k    0     0   276k      0  0:00:09  0:00:01  0:00:08  508k\r",
      " 35 2726k   35  959k    0     0   465k      0  0:00:05  0:00:02  0:00:03  605k\r",
      " 50 2726k   50 1375k    0     0   449k      0  0:00:06  0:00:03  0:00:03  532k\r",
      " 69 2726k   69 1903k    0     0   467k      0  0:00:05  0:00:04  0:00:01  529k\r",
      " 96 2726k   96 2623k    0     0   520k      0  0:00:05  0:00:05 --:--:--  574k\r",
      "100 2726k  100 2726k    0     0   528k      0  0:00:05  0:00:05 --:--:--  591k\r\n",
      "\r\n",
      "[5/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1505.csv --> hotl1505.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1505.csv\r\n",
      "\r",
      "  9 2739k    9  271k    0     0   308k      0  0:00:08 --:--:--  0:00:08  308k\r",
      " 43 2739k   43 1183k    0     0   630k      0  0:00:04  0:00:01  0:00:03  912k\r",
      " 77 2739k   77 2134k    0     0   732k      0  0:00:03  0:00:02  0:00:01  916k\r",
      "100 2739k  100 2739k    0     0   751k      0  0:00:03  0:00:03 --:--:--  892k\r\n",
      "\r\n",
      "[6/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1506.csv --> hotl1506.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1506.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 22 2816k   22  623k    0     0   508k      0  0:00:05  0:00:01  0:00:04  705k\r",
      " 45 2816k   45 1279k    0     0   574k      0  0:00:04  0:00:02  0:00:02  678k\r",
      " 65 2816k   65 1855k    0     0   566k      0  0:00:04  0:00:03  0:00:01  632k\r",
      " 87 2816k   87 2463k    0     0   579k      0  0:00:04  0:00:04 --:--:--  630k\r",
      "100 2816k  100 2816k    0     0   606k      0  0:00:04  0:00:04 --:--:--  655k\r\n",
      "\r\n",
      "[7/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1507.csv --> hotl1507.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1507.csv\r\n",
      "\r",
      "  6 2813k    6  175k    0     0   290k      0  0:00:09 --:--:--  0:00:09  290k\r",
      " 22 2813k   22  623k    0     0   394k      0  0:00:07  0:00:01  0:00:06  458k\r",
      " 42 2813k   42 1199k    0     0   461k      0  0:00:06  0:00:02  0:00:04  512k\r",
      " 70 2813k   70 1983k    0     0   553k      0  0:00:05  0:00:03  0:00:02  606k\r",
      "100 2813k  100 2813k    0     0   615k      0  0:00:04  0:00:04 --:--:--  664k\r\n",
      "\r\n",
      "[8/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1508.csv --> hotl1508.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1508.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  4 2892k    4  143k    0     0   133k      0  0:00:21  0:00:01  0:00:20  133k\r",
      "  9 2892k    9  271k    0     0   135k      0  0:00:21  0:00:02  0:00:19  135k\r",
      " 23 2892k   23  687k    0     0   228k      0  0:00:12  0:00:03  0:00:09  229k\r",
      " 55 2892k   55 1615k    0     0   403k      0  0:00:07  0:00:04  0:00:03  403k\r",
      " 94 2892k   94 2735k    0     0   546k      0  0:00:05  0:00:05 --:--:--  546k\r",
      "100 2892k  100 2892k    0     0   558k      0  0:00:05  0:00:05 --:--:--  670k\r\n",
      "\r\n",
      "[9/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1509.csv --> hotl1509.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1509.csv\r\n",
      "\r",
      " 13 2918k   13  383k    0     0   440k      0  0:00:06 --:--:--  0:00:06  440k\r",
      " 33 2918k   33  975k    0     0   533k      0  0:00:05  0:00:01  0:00:04  619k\r",
      " 63 2918k   63 1839k    0     0   650k      0  0:00:04  0:00:02  0:00:02  744k\r",
      " 88 2918k   88 2591k    0     0   675k      0  0:00:04  0:00:03  0:00:01  744k\r",
      "100 2918k  100 2918k    0     0   673k      0  0:00:04  0:00:04 --:--:--  732k\r\n",
      "\r\n",
      "[10/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1510.csv --> hotl1510.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1510.csv\r\n",
      "\r",
      "  6 2641k    6  175k    0     0   364k      0  0:00:07 --:--:--  0:00:07  364k\r",
      " 36 2641k   36  975k    0     0   649k      0  0:00:04  0:00:01  0:00:03  785k\r",
      " 72 2641k   72 1919k    0     0   768k      0  0:00:03  0:00:02  0:00:01  865k\r",
      "100 2641k  100 2641k    0     0   808k      0  0:00:03  0:00:03 --:--:--  885k\r\n",
      "\r\n",
      "[11/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1511.csv --> hotl1511.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1511.csv\r\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 17 2875k   17  495k    0     0   409k      0  0:00:07  0:00:01  0:00:06  607k\r",
      " 33 2875k   33  975k    0     0   441k      0  0:00:06  0:00:02  0:00:04  537k\r",
      " 49 2875k   49 1423k    0     0   443k      0  0:00:06  0:00:03  0:00:03  505k\r",
      " 86 2875k   86 2479k    0     0   588k      0  0:00:04  0:00:04 --:--:--  649k\r",
      "100 2875k  100 2875k    0     0   646k      0  0:00:04  0:00:04 --:--:--  709k\r\n",
      "\r\n",
      "[12/12]: https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1512.csv --> hotl1512.csv\r\n",
      "--_curl_--https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl1512.csv\r\n",
      "\r",
      " 10 2963k   10  319k    0     0   421k      0  0:00:07 --:--:--  0:00:07  421k\r",
      " 65 2963k   65 1942k    0     0  1103k      0  0:00:02  0:00:01  0:00:01 1618k\r",
      "100 2963k  100 2963k    0     0  1271k      0  0:00:02  0:00:02 --:--:-- 1680k\r\n"
     ]
    }
   ],
   "source": [
    "curl -O -L https://raw.githubusercontent.com/utdata/cli-tools/master/hoteltax/data/hotl15[01-12].csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pulled down all 12 files. Now we can take a look to make sure we have all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 67304\r\n",
      "-rw-r--r--  1 christian  staff  2836275 Jul 10 22:59 hotl1501.csv\r\n",
      "-rw-r--r--  1 christian  staff  2798250 Jul 10 22:59 hotl1502.csv\r\n",
      "-rw-r--r--  1 christian  staff  2804425 Jul 10 22:59 hotl1503.csv\r\n",
      "-rw-r--r--  1 christian  staff  2791750 Jul 10 22:59 hotl1504.csv\r\n",
      "-rw-r--r--  1 christian  staff  2805075 Jul 10 22:59 hotl1505.csv\r\n",
      "-rw-r--r--  1 christian  staff  2883725 Jul 10 22:59 hotl1506.csv\r\n",
      "-rw-r--r--  1 christian  staff  2880800 Jul 10 22:59 hotl1507.csv\r\n",
      "-rw-r--r--  1 christian  staff  2961725 Jul 10 22:59 hotl1508.csv\r\n",
      "-rw-r--r--  1 christian  staff  2988375 Jul 10 22:59 hotl1509.csv\r\n",
      "-rw-r--r--  1 christian  staff  2705300 Jul 10 22:59 hotl1510.csv\r\n",
      "-rw-r--r--  1 christian  staff  2944500 Jul 10 22:59 hotl1511.csv\r\n",
      "-rw-r--r--  1 christian  staff  3034525 Jul 10 22:59 hotl1512.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head to look at a file\n",
    "\n",
    "Let's take a look at the top of the first file. We'll use a command called `head` which looks at the first ten lines of the file. We'll also show that tab complete works here, so type in head hot and then hit tab, and you'll get a pop-up that shows available files to choose from. Choose the right one, then use shift-return to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32050067050,\"COASTAL WAVES VACATIONS, LLC                      \",\"3616 7 MILE RD                          \",\"GALVESTON           \",\"TX\",\"77554\",084,00010,\" COASTAL WAVES VACATIONS                          \",\"4158 GREEN HERON DR                     \",\"GALVESTON           \",\"TX\",\"77554\",084,    1,       530.00,       530.00\r",
      "\r\n",
      "32049649729,\"ALL SEASONS RENTALS,  INC.                        \",\"15113 BAT HAWK CIR                      \",\"AUSTIN              \",\"TX\",\"78738\",227,00022,\" CROSSING C                                       \",\"613 HI CIR N                            \",\"HORSESHOE BAY       \",\"TX\",\"78657\",150,    1,         0.00,         0.00\r",
      "\r\n",
      "32039987733,\"TIRUPATI LODGING CORP.                            \",\"1407 S MAIN ST                          \",\"HIGHLANDS           \",\"TX\",\"77562\",101,00001,\" HIGHLANDS SUITES                                 \",\"1407 S MAIN ST                          \",\"HIGHLANDS           \",\"TX\",\"77562\",101,   31,     27264.87,     22864.87\r",
      "\r\n",
      "32001947285,\"IRMA A HARTMAN                                    \",\"2423 E MAIN ST                          \",\"EAGLE PASS          \",\"TX\",\"78852\",159,00001,\" HOLLY INN                                        \",\"2423 E MAIN ST                          \",\"EAGLE PASS          \",\"TX\",\"78852\",159,   70,      9553.98,      9553.98\r",
      "\r\n",
      "32046829167,\"SPI RENTALS, LLC                                  \",\"104 W BAHAMA ST STE B                   \",\"S PADRE ISLE        \",\"TX\",\"78597\",031,00046,\" SPI RENTALS, LLC - BEACH                         \",\"6401B BEACH DR                          \",\"SOUTH PADRE ISLAND  \",\"TX\",\"78597\",031,    1,      2670.00,      2670.00\r",
      "\r\n",
      "32015454328,\"WILLIAM T HOVESTADT                               \",\"PO BOX 310279                           \",\"NEW BRAUNFELS       \",\"TX\",\"78131\",046,00011,\" W T H INVESTMENTS                                \",\"777 CLOUD LN                            \",\"NEW BRAUNFELS       \",\"TX\",\"78130\",094,    1,      7589.00,      7589.00\r",
      "\r\n",
      "32009496855,\"MARCUS C STARKEY                                  \",\"PO BOX 1780                             \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,00191,\"(LC28) MICHAEL OR DAWN COACH                      \",\"6877 STATE HIGHWAY 361                  \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,    1,         0.00,         0.00\r",
      "\r\n",
      "32009496855,\"MARCUS C STARKEY                                  \",\"PO BOX 1780                             \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,00189,\"(LC42) STEVEN GATTO                               \",\"6877 STATE HIGHWAY 361                  \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,    1,      1524.17,         0.00\r",
      "\r\n",
      "32009496855,\"MARCUS C STARKEY                                  \",\"PO BOX 1780                             \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,00155,\"(PB 114) TERRY L CARTER                           \",\"2012 HWY 361 #114                       \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,    1,      1550.00,         0.00\r",
      "\r\n",
      "32009496855,\"MARCUS C STARKEY                                  \",\"PO BOX 1780                             \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,00156,\"(PB 205) LARRY OR VICKY MURPHY                    \",\"2012 HWY 361 # 205                      \",\"PORT ARANSAS        \",\"TX\",\"78373\",178,    1,      1653.23,         0.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "head hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this looks like something, but we don't have a header row, which sucks. We can compare it against our [table layout](https://github.com/utdata/cli-tools/blob/master/hoteltax/HOTELTAX_LYOT.TXT):\n",
    "\n",
    "```\n",
    "Column_Order|Column_Description|Data_Type|Size\n",
    "Col01|Taxpayer Number|Number|11\n",
    "Col02|Taxpayer Name|Char|50\n",
    "Col03|Taxpayer Address|Char|40\n",
    "Col04|Taxpayer City|Char|20\n",
    "Col05|Taxpayer State|Char|2\n",
    "Col06|Taxpayer Zip Code|Number|5\n",
    "Col07|Taxpayer County|Number|3\n",
    "Col08|Outlet Number|Number|5\n",
    "Col09|Location Name|Char|50\n",
    "Col10|Location Address|Char|40\n",
    "Col11|Location City|Char|20\n",
    "Col12|Location State|Char|2\n",
    "Col13|Location Zip Code|Number|5\n",
    "Col14|Location County|Number|3\n",
    "Col15|Location Room Capacity|Number|5\n",
    "Col16|Location Tot Room Receipts|Number|13\n",
    "Col17|Location Taxable Receipts|Number|13\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add a header row to all of these files or we'll have problems later. This is one place that we are making changes to the original file, though we'll make a backup while we're doing it, and then remove them. We could do this manually, but even with a text editor, it takes a long time to just save the changes.\n",
    "\n",
    "We'll use a program called `sed`. I'll be honest, this took me a couple of hours to figure out, especially since Mac handles `sed -i` differently than unix, and I thought I was going crazy. So, this is possibly a Mac-only solution.\n",
    "\n",
    "First, we need the text that will go in the header row. I built this by hand based on the layout file above:\n",
    "\n",
    "```\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "```\n",
    "\n",
    "Here is the command to change one of the files, and then I'll explain it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's take a look at that file to make sure the header line was added properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32050067050,\"COASTAL WAVES VACATIONS, LLC                      \",\"3616 7 MILE RD                          \",\"GALVESTON           \",\"TX\",\"77554\",084,00010,\" COASTAL WAVES VACATIONS                          \",\"4158 GREEN HERON DR                     \",\"GALVESTON           \",\"TX\",\"77554\",084,    1,       530.00,       530.00\r",
      "\r\n",
      "32049649729,\"ALL SEASONS RENTALS,  INC.                        \",\"15113 BAT HAWK CIR                      \",\"AUSTIN              \",\"TX\",\"78738\",227,00022,\" CROSSING C                                       \",\"613 HI CIR N                            \",\"HORSESHOE BAY       \",\"TX\",\"78657\",150,    1,         0.00,         0.00\r",
      "\r\n",
      "32039987733,\"TIRUPATI LODGING CORP.                            \",\"1407 S MAIN ST                          \",\"HIGHLANDS           \",\"TX\",\"77562\",101,00001,\" HIGHLANDS SUITES                                 \",\"1407 S MAIN ST                          \",\"HIGHLANDS           \",\"TX\",\"77562\",101,   31,     27264.87,     22864.87\r",
      "\r\n",
      "32001947285,\"IRMA A HARTMAN                                    \",\"2423 E MAIN ST                          \",\"EAGLE PASS          \",\"TX\",\"78852\",159,00001,\" HOLLY INN                                        \",\"2423 E MAIN ST                          \",\"EAGLE PASS          \",\"TX\",\"78852\",159,   70,      9553.98,      9553.98\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "head -n 5 hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks good. Now, let's do this for the other 11 files. (We don't want to do the first one again, or we'll add the header twice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1502.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1503.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1504.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1505.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1506.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1507.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1508.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1509.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1510.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1511.csv\n",
    "sed -i '.bak' '1i \\\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "' hotl1512.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one thing about this ... we created a bunch of *.bak* files as backups that we'll need to get rid of. To do so, we get to use the power of `rm`.\n",
    "\n",
    "Let's look at all the files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 134608\r\n",
      "-rw-r--r--  1 christian  staff  2836569 Jul 10 22:59 hotl1501.csv\r\n",
      "-rw-r--r--  1 christian  staff  2836275 Jul 10 22:59 hotl1501.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2798544 Jul 10 22:59 hotl1502.csv\r\n",
      "-rw-r--r--  1 christian  staff  2798250 Jul 10 22:59 hotl1502.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2804719 Jul 10 22:59 hotl1503.csv\r\n",
      "-rw-r--r--  1 christian  staff  2804425 Jul 10 22:59 hotl1503.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2792044 Jul 10 22:59 hotl1504.csv\r\n",
      "-rw-r--r--  1 christian  staff  2791750 Jul 10 22:59 hotl1504.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2805369 Jul 10 22:59 hotl1505.csv\r\n",
      "-rw-r--r--  1 christian  staff  2805075 Jul 10 22:59 hotl1505.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2884019 Jul 10 22:59 hotl1506.csv\r\n",
      "-rw-r--r--  1 christian  staff  2883725 Jul 10 22:59 hotl1506.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2881094 Jul 10 22:59 hotl1507.csv\r\n",
      "-rw-r--r--  1 christian  staff  2880800 Jul 10 22:59 hotl1507.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2962019 Jul 10 22:59 hotl1508.csv\r\n",
      "-rw-r--r--  1 christian  staff  2961725 Jul 10 22:59 hotl1508.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2988669 Jul 10 22:59 hotl1509.csv\r\n",
      "-rw-r--r--  1 christian  staff  2988375 Jul 10 22:59 hotl1509.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2705594 Jul 10 22:59 hotl1510.csv\r\n",
      "-rw-r--r--  1 christian  staff  2705300 Jul 10 22:59 hotl1510.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  2944794 Jul 10 22:59 hotl1511.csv\r\n",
      "-rw-r--r--  1 christian  staff  2944500 Jul 10 22:59 hotl1511.csv.bak\r\n",
      "-rw-r--r--  1 christian  staff  3034819 Jul 10 22:59 hotl1512.csv\r\n",
      "-rw-r--r--  1 christian  staff  3034525 Jul 10 22:59 hotl1512.csv.bak\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove all the files with .bak in the name, and then `ls` the directory again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 67304\r\n",
      "-rw-r--r--  1 christian  staff  2836569 Jul 10 22:59 hotl1501.csv\r\n",
      "-rw-r--r--  1 christian  staff  2798544 Jul 10 22:59 hotl1502.csv\r\n",
      "-rw-r--r--  1 christian  staff  2804719 Jul 10 22:59 hotl1503.csv\r\n",
      "-rw-r--r--  1 christian  staff  2792044 Jul 10 22:59 hotl1504.csv\r\n",
      "-rw-r--r--  1 christian  staff  2805369 Jul 10 22:59 hotl1505.csv\r\n",
      "-rw-r--r--  1 christian  staff  2884019 Jul 10 22:59 hotl1506.csv\r\n",
      "-rw-r--r--  1 christian  staff  2881094 Jul 10 22:59 hotl1507.csv\r\n",
      "-rw-r--r--  1 christian  staff  2962019 Jul 10 22:59 hotl1508.csv\r\n",
      "-rw-r--r--  1 christian  staff  2988669 Jul 10 22:59 hotl1509.csv\r\n",
      "-rw-r--r--  1 christian  staff  2705594 Jul 10 22:59 hotl1510.csv\r\n",
      "-rw-r--r--  1 christian  staff  2944794 Jul 10 22:59 hotl1511.csv\r\n",
      "-rw-r--r--  1 christian  staff  3034819 Jul 10 22:59 hotl1512.csv\r\n"
     ]
    }
   ],
   "source": [
    "rm *.bak\n",
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32050067050,\"COASTAL WAVES VACATIONS, LLC                      \",\"3616 7 MILE RD                          \",\"GALVESTON           \",\"TX\",\"77554\",084,00010,\" COASTAL WAVES VACATIONS                          \",\"4158 GREEN HERON DR                     \",\"GALVESTON           \",\"TX\",\"77554\",084,    1,       530.00,       530.00\r",
      "\r\n",
      "32049649729,\"ALL SEASONS RENTALS,  INC.                        \",\"15113 BAT HAWK CIR                      \",\"AUSTIN              \",\"TX\",\"78738\",227,00022,\" CROSSING C                                       \",\"613 HI CIR N                            \",\"HORSESHOE BAY       \",\"TX\",\"78657\",150,    1,         0.00,         0.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "head -n 3 hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things about that file. Note that Col02, Taxpayer name is 50 characters long. Look at the first line of data:\n",
    "\n",
    "```\n",
    "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\n",
    "32050067050,\"COASTAL WAVES VACATIONS, LLC                      \",\"3616 7 MILE RD                          \",\"GALVESTON           \",\"TX\",\"77554\",084,00010,\" COASTAL WAVES VACATIONS                          \",\"4158 GREEN HERON DR                     \",\"GALVESTON           \",\"TX\",\"77554\",084,    1,       530.00,       530.00\n",
    "```\n",
    "\n",
    "Notice anything about that \"COASTAL WAVES VACATIONS, LLC\" name? That name is in quotes, but look where quote mark closes. That field uses the full 50 characters, filled in with spaces. Same for the address, and all the other fields. This is one of the things **csvkit** can help us with, cleaning up and normalizing a csv file.\n",
    "\n",
    "Let's move out of our data directory and create a new one to put our processed data into. We don't ever want to change our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# we use the -p here so it won't error if it already exists\n",
    "mkdir -p data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to have the [csvkit docs](https://csvkit.readthedocs.io) open as a reference as we go through this.\n",
    "\n",
    "Csvkit has a command called `in2csv` that not only converts .xlsx files to .csv, it also cleans up .csv files like all the spaces in our name. We want to use this technique on our files, but at 2.8Ms, it would take some time to do one file, much less all 12. It's worth doing if you have time. We don't.\n",
    "\n",
    "Remember that our goal is to look at all the Austin hotels? Well, we can cut our files down to the smaller Austin files and then clean them up at the same time. To do this, we need to find out un which column to search for Austin.\n",
    "\n",
    "We can see from our table layout above, that the 11th column is the Location City, but let's use `csvcut -n` to peak at the header row of the first file to confirm. the `-n` stands for `--names`, because it is usually used to see the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Taxpayer Number\r\n",
      "  2: Taxpayer Name\r\n",
      "  3: Taxpayer Address\r\n",
      "  4: Taxpayer City\r\n",
      "  5: Taxpayer State\r\n",
      "  6: Taxpayer Zip Code\r\n",
      "  7: Taxpayer County\r\n",
      "  8: Outlet Number\r\n",
      "  9: Location Name\r\n",
      " 10: Location Address\r\n",
      " 11: Location City\r\n",
      " 12: Location State\r\n",
      " 13: Location Zip Code\r\n",
      " 14: Location County\r\n",
      " 15: Location Room Capacity\r\n",
      " 16: Location Tot Room Receipts\r\n",
      " 17: Location Taxable Receipts\r\n"
     ]
    }
   ],
   "source": [
    "csvcut -n data/hotl1501.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we can see `Location City` is in the 11th column, which looks good. We can use `csvgrep` to find the AUSTIN rows.\n",
    "\n",
    "Grep is a command-line tool for regular expressions, and `csvgrep` works the same way. It needs a couple of arguments:\n",
    "\n",
    "* `-c` is which column to search. We want `11`.\n",
    "* `-m` you would use to match an exact string. We could instead use `-r` to build a regular expression.\n",
    "\n",
    "We know we need column 11, but the match word will be tricky. We can't search for just the word \"AUSTIN\" because the \n",
    "\n",
    "The other thing we are going to do is to **pipe** the result into another command, `head` in this case. This is so we can just look at the first couple of lines to test our output before using it. This **pipe** concept is really important: You can take the \"out\" result of command and make it the \"in\" command of another, and you can string these together into a pipeline. That's what we're working on here, piece by piece ... a pipeline to cut and clean our files.\n",
    "\n",
    "So, our `csvgrep` command searches the 11th column for the word AUSTIN at the beginning (the ^). We then pipe it into `head` and use the `-n` flag to show just 5 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32016602719,BHAKTA DAYARAM                                    ,2627 MANOR RD                           ,AUSTIN              ,TX,78722,227,00001,ACE MOTEL                                         ,2627 MANOR RD                           ,AUSTIN              ,TX,78722,227,   27,      9165.00,      8580.00\r\n",
      "32016658448,SIDNEY CORINNE LOCK                               ,4300 AVENUE G                           ,AUSTIN              ,TX,78751,227,00005,ADAMS HOUSE BED & BREAKFAST                       ,4300 AVENUE G                           ,AUSTIN              ,TX,78751,227,    3,     14903.00,     13544.00\r\n",
      "32043492993,AMANDA K CRIBBS                                   ,4202 FLAGSTAFF DR                       ,AUSTIN              ,TX,78759,227,00007,ALLANDALE RENTALS                                 ,1107A BRENTWOOD ST                      ,AUSTIN              ,TX,78757,227,    2,       250.00,       250.00\r\n",
      "32043492993,AMANDA K CRIBBS                                   ,4202 FLAGSTAFF DR                       ,AUSTIN              ,TX,78759,227,00009,ALLANDALE RENTALS                                 ,11900 ALOE VERA TRL                     ,AUSTIN              ,TX,78750,246,    8,      2728.00,      2728.00\r\n"
     ]
    }
   ],
   "source": [
    "csvgrep -c 11 -r '^AUSTIN' data/hotl1501.csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OK, that looks like we are getting the right row. Now we are going to pipe that result into `in2csv` and then again into `head` to see what it looks like.\n",
    "\n",
    "In this case, `in2csv` needs a `-f` flag for filetype, which we will set as `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxpayer Number,Taxpayer Name,Taxpayer Address,Taxpayer City,Taxpayer State,Taxpayer Zip Code,Taxpayer County,Outlet Number,Location Name,Location Address,Location City,Location State,Location Zip Code,Location County,Location Room Capacity,Location Tot Room Receipts,Location Taxable Receipts\r\n",
      "32016602719,BHAKTA DAYARAM,2627 MANOR RD,AUSTIN,TX,78722,227,00001,ACE MOTEL,2627 MANOR RD,AUSTIN,TX,78722,227,27,9165.0,8580.0\r\n",
      "32016658448,SIDNEY CORINNE LOCK,4300 AVENUE G,AUSTIN,TX,78751,227,00005,ADAMS HOUSE BED & BREAKFAST,4300 AVENUE G,AUSTIN,TX,78751,227,3,14903.0,13544.0\r\n",
      "32043492993,AMANDA K CRIBBS,4202 FLAGSTAFF DR,AUSTIN,TX,78759,227,00007,ALLANDALE RENTALS,1107A BRENTWOOD ST,AUSTIN,TX,78757,227,2,250.0,250.0\r\n",
      "32043492993,AMANDA K CRIBBS,4202 FLAGSTAFF DR,AUSTIN,TX,78759,227,00009,ALLANDALE RENTALS,11900 ALOE VERA TRL,AUSTIN,TX,78750,246,8,2728.0,2728.0\r\n"
     ]
    }
   ],
   "source": [
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1501.csv | in2csv -f csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference in the files now? All the bad space is gone. We can take that command above and instead of piping it into `head`, we can redirect it into a new file in the data-done folder. We do this with `>` and then specify the file location, which we'll call `hotl1501-austin.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1501.csv | in2csv -f csv > data-done/hotl1501-atx.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the new `data-done` directory to see that the finished file is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4504\r\n",
      "-rw-r--r--  1 christian  staff  1162130 Jul 10 22:39 austin-hotels.csv\r\n",
      "-rw-r--r--  1 christian  staff    89362 Jul 10 23:01 hotl1501-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    88878 Jul 10 22:13 hotl1502-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    93104 Jul 10 22:13 hotl1503-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    91828 Jul 10 22:13 hotl1504-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    90653 Jul 10 22:13 hotl1505-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    89636 Jul 10 22:13 hotl1506-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    86633 Jul 10 22:13 hotl1507-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    90431 Jul 10 22:13 hotl1508-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    98754 Jul 10 22:13 hotl1509-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    95913 Jul 10 22:13 hotl1510-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff   101552 Jul 10 22:13 hotl1511-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff   100217 Jul 10 22:13 hotl1512-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff        0 Jul 10 22:31 test.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -l data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OK, let's go ahead and process all of the files so we have clean versions of the Austin records. There is definitely a better way to do this with a loop of some sort, but I don't know how. Yet.\n",
    "\n",
    "When I set this up, I just copied that first one over 11 more times, then updated the file names in both places on each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Make sure you get the file names right\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1501.csv | in2csv -f csv > data-done/hotl1501-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1502.csv | in2csv -f csv > data-done/hotl1502-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1503.csv | in2csv -f csv > data-done/hotl1503-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1504.csv | in2csv -f csv > data-done/hotl1504-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1505.csv | in2csv -f csv > data-done/hotl1505-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1506.csv | in2csv -f csv > data-done/hotl1506-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1507.csv | in2csv -f csv > data-done/hotl1507-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1508.csv | in2csv -f csv > data-done/hotl1508-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1509.csv | in2csv -f csv > data-done/hotl1509-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1510.csv | in2csv -f csv > data-done/hotl1510-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1511.csv | in2csv -f csv > data-done/hotl1511-atx.csv\n",
    "csvgrep -c 11 -r \"^AUSTIN\" data/hotl1512.csv | in2csv -f csv > data-done/hotl1512-atx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4504\r\n",
      "-rw-r--r--  1 christian  staff  1162130 Jul 10 22:39 austin-hotels.csv\r\n",
      "-rw-r--r--  1 christian  staff    89362 Jul 10 23:01 hotl1501-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    88878 Jul 10 23:01 hotl1502-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    93104 Jul 10 23:01 hotl1503-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    91828 Jul 10 23:01 hotl1504-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    90653 Jul 10 23:01 hotl1505-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    89636 Jul 10 23:01 hotl1506-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    86633 Jul 10 23:01 hotl1507-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    90431 Jul 10 23:01 hotl1508-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    98754 Jul 10 23:02 hotl1509-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff    95913 Jul 10 23:02 hotl1510-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff   101552 Jul 10 23:02 hotl1511-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff   100217 Jul 10 23:02 hotl1512-atx.csv\r\n",
      "-rw-r--r--  1 christian  staff        0 Jul 10 22:31 test.csv\r\n"
     ]
    }
   ],
   "source": [
    "# making sure they are all there\n",
    "ls -l data-done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack into a single file\n",
    "\n",
    "Now we can use [csvstack](https://csvkit.readthedocs.io/en/540/scripts/csvstack.html) to combine all the files into one big file.\n",
    "\n",
    "* **-g** flag lets us create a new column and give a value to each row that defines which file it came from. In our case, we need to know what month it came from, so we'll list all the months.\n",
    "* **-n** let's us name that group column. We'll call it Month.\n",
    "\n",
    "Then we list all the files we want to put together. When when use **-g**, which have to have the same number of groupings as we do input files.\n",
    "\n",
    "I'm breaking this command up into multiple lines using \"\\\" at the end so you can see the whole command. The group names and the files need to be in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "csvstack -n Month -g \\\n",
    "January,February,March,April,May,June,July,August,September,October,November,December \\\n",
    "data-done/hotl1501-atx.csv data-done/hotl1502-atx.csv data-done/hotl1503-atx.csv \\\n",
    "data-done/hotl1504-atx.csv data-done/hotl1505-atx.csv data-done/hotl1506-atx.csv \\\n",
    "data-done/hotl1507-atx.csv data-done/hotl1508-atx.csv data-done/hotl1509-atx.csv \\\n",
    "data-done/hotl1510-atx.csv data-done/hotl1511-atx.csv data-done/hotl1512-atx.csv \\\n",
    "> data-done/austin-hotels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick stats on files\n",
    "\n",
    "We'll use [csvstat](https://csvkit.readthedocs.io/en/540/scripts/csvstat.html) to take a closer look at the combined file. Sometimes the result is all you need for a story ... the min, max, sum, mean and median of a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Month\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 12\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tNovember:\t612\r\n",
      "\t\tDecember:\t603\r\n",
      "\t\tSeptember:\t593\r\n",
      "\t\tOctober:\t575\r\n",
      "\t\tMarch:\t555\r\n",
      "\tMax length: 9\r\n",
      "  2. Taxpayer Number\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 10204561905\r\n",
      "\tMax: 32059158348\r\n",
      "\tSum: 187936198875413\r\n",
      "\tMean: 28087908963.59483\r\n",
      "\tMedian: 32047098168\r\n",
      "\tStandard Deviation: 7532652034.898627\r\n",
      "\tUnique values: 252\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t32049933412:\t2302\r\n",
      "\t\t32043490237:\t276\r\n",
      "\t\t32052153940:\t275\r\n",
      "\t\t32022337540:\t264\r\n",
      "\t\t12016274339:\t144\r\n",
      "  3. Taxpayer Name\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 256\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTURNKEY VACATION RENTALS, INC.:\t2302\r\n",
      "\t\tVACATIONCAKE LLC:\t276\r\n",
      "\t\tEMERSON GUEST PROPERTIES LLC:\t275\r\n",
      "\t\tCHEREEN FISHER:\t264\r\n",
      "\t\tESA P PORTFOLIO OPERATING LESSEE LLC:\t120\r\n",
      "\tMax length: 50\r\n",
      "  4. Taxpayer Address\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 225\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t4544 S LAMAR BLVD STE G300:\t1117\r\n",
      "\t\t4544 S LAMAR BLVD BLDG 300:\t871\r\n",
      "\t\t3006 BEE CAVES RD STE D310:\t314\r\n",
      "\t\t1709 BLUEBONNET LN:\t276\r\n",
      "\t\t707 JOSEPHINE ST:\t275\r\n",
      "\tMax length: 36\r\n",
      "  5. Taxpayer City\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 56\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tAUSTIN:\t4932\r\n",
      "\t\tMERRILLVILLE:\t234\r\n",
      "\t\tGREENWOOD VLG:\t167\r\n",
      "\t\tCHARLOTTE:\t156\r\n",
      "\t\tIRVING:\t144\r\n",
      "\tMax length: 13\r\n",
      "  6. Taxpayer State\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 25\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTX:\t5648\r\n",
      "\t\tIN:\t234\r\n",
      "\t\tCO:\t201\r\n",
      "\t\tNC:\t156\r\n",
      "\t\tCA:\t111\r\n",
      "\tMax length: 2\r\n",
      "  7. Taxpayer Zip Code\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 110\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t78745:\t2033\r\n",
      "\t\t78704:\t796\r\n",
      "\t\t78701:\t522\r\n",
      "\t\t78746:\t433\r\n",
      "\t\t46410:\t234\r\n",
      "\tMax length: 5\r\n",
      "  8. Taxpayer County\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 14\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t227:\t4950\r\n",
      "\t\t000:\t1043\r\n",
      "\t\t057:\t248\r\n",
      "\t\t101:\t131\r\n",
      "\t\t246:\t117\r\n",
      "\tMax length: 3\r\n",
      "  9. Outlet Number\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 278\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t00001:\t1801\r\n",
      "\t\t00002:\t642\r\n",
      "\t\t00003:\t227\r\n",
      "\t\t00004:\t164\r\n",
      "\t\t00008:\t135\r\n",
      "\tMax length: 5\r\n",
      " 10. Location Name\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 592\r\n",
      "\t5 most frequent values:\r\n",
      "\t\tTURNKEY VACATION RENTALS:\t534\r\n",
      "\t\tTOP TRIP RENTALS:\t143\r\n",
      "\t\tCHEREEN FISHER:\t121\r\n",
      "\t\tTURNKEY VACATION RENTALS LLC:\t87\r\n",
      "\t\tRASMUSSEN JOEL & DANI LIVING TRUST:\t60\r\n",
      "\tMax length: 50\r\n",
      " 11. Location Address\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tUnique values: 654\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t8212 BARTON CLUB DR:\t35\r\n",
      "\t\t300 E 4TH ST:\t24\r\n",
      "\t\t4140 GOVERNORS ROW:\t24\r\n",
      "\t\t13087 N HIGHWAY 183:\t24\r\n",
      "\t\t3335 FAR VIEW DR:\t24\r\n",
      "\tMax length: 32\r\n",
      " 12. Location City\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: AUSTIN\r\n",
      " 13. Location State\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: TX\r\n",
      " 14. Location Zip Code\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 78676\r\n",
      "\tMax: 78759\r\n",
      "\tSum: 526737038\r\n",
      "\tMean: 78723.21596173965\r\n",
      "\tMedian: 78705\r\n",
      "\tStandard Deviation: 22.25971661101686\r\n",
      "\tUnique values: 39\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t78704:\t1473\r\n",
      "\t\t78701:\t798\r\n",
      "\t\t78702:\t508\r\n",
      "\t\t78703:\t371\r\n",
      "\t\t78759:\t294\r\n",
      " 15. Location County\r\n",
      "\t<class 'str'>\r\n",
      "\tNulls: False\r\n",
      "\tValues: 105, 227, 178, 246, 011\r\n",
      " 16. Location Room Capacity\r\n",
      "\t<class 'int'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 1\r\n",
      "\tMax: 1012\r\n",
      "\tSum: 319776\r\n",
      "\tMean: 47.79195934837842\r\n",
      "\tMedian: 4\r\n",
      "\tStandard Deviation: 96.54025112765952\r\n",
      "\tUnique values: 143\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t1:\t1493\r\n",
      "\t\t2:\t920\r\n",
      "\t\t3:\t905\r\n",
      "\t\t4:\t448\r\n",
      "\t\t5:\t235\r\n",
      " 17. Location Tot Room Receipts\r\n",
      "\t<class 'float'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 0.0\r\n",
      "\tMax: 8846099.89\r\n",
      "\tSum: 1018272027.329999\r\n",
      "\tMean: 152185.32765356434\r\n",
      "\tMedian: 4595.0\r\n",
      "\tStandard Deviation: 467586.19497391686\r\n",
      "\tUnique values: 5338\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t0.0:\t1189\r\n",
      "\t\t2500.0:\t11\r\n",
      "\t\t3395.0:\t10\r\n",
      "\t\t2179.0:\t6\r\n",
      "\t\t3000.0:\t6\r\n",
      " 18. Location Taxable Receipts\r\n",
      "\t<class 'float'>\r\n",
      "\tNulls: False\r\n",
      "\tMin: 0.0\r\n",
      "\tMax: 8768869.74\r\n",
      "\tSum: 922927594.399999\r\n",
      "\tMean: 137935.67395008204\r\n",
      "\tMedian: 4201.74\r\n",
      "\tStandard Deviation: 440751.17680702644\r\n",
      "\tUnique values: 5161\r\n",
      "\t5 most frequent values:\r\n",
      "\t\t0.0:\t1406\r\n",
      "\t\t900.0:\t6\r\n",
      "\t\t1200.0:\t5\r\n",
      "\t\t2031.0:\t3\r\n",
      "\t\t3597.0:\t3\r\n",
      "\r\n",
      "Row count: 6691\r\n"
     ]
    }
   ],
   "source": [
    "csvstat data-done/austin-hotels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result, and possible next steps\n",
    "\n",
    "You can already see a couple of things here.\n",
    "\n",
    "* The most a single hotel reported in 2015 was 8,846,099.\n",
    "* The mean (or average) reported by all establishments was 152,185, but given the median is 4,595 there are many establishments that did not make that much money.\n",
    "\n",
    "Now your single `austin-hotels` file can be analyzed so you are looking at one year of data all together.\n",
    "\n",
    "By having this all in this notebook, you can run the whole process over again by going to the Kernel menu and choosing **Restart and Run All**.\n",
    "\n",
    "If you find you had a mistake somewhere along the line, you can fix it, then **Restart and Run All**.\n",
    "\n",
    "Imagine if you had done all this by hand in Excel, and then found you made an error early in the process. Or, worse yet, you didn't discover you made an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
